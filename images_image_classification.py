# -*- coding: utf-8 -*-
"""Images: Image classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y1Q8PWVGxgq4mYRns3-_lGu31ELOjsbe
"""

import tensorflow as tf 

import os
import numpy as np
import matplotlib.pyplot as plt

_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'

path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)

PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')

PATH

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')

train_cats_dir = os.path.join(train_dir, 'cats')
train_dogs_dir = os.path.join(train_dir, 'dogs')
validation_cats_dir = os.path.join(validation_dir, 'cats')
validation_dogs_dir = os.path.join(validation_dir, 'dogs')

num_cats_tr = len(os.listdir(train_cats_dir))
num_dogs_tr = len(os.listdir(train_dogs_dir))

num_cats_val = len(os.listdir(validation_cats_dir))
num_dogs_val = len(os.listdir(validation_dogs_dir))

total_train = num_cats_tr + num_dogs_tr
total_val = num_cats_val + num_dogs_val

print('total training cat images:', num_cats_tr)
print('total training dog images:', num_dogs_tr)

print('total validation cat images:', num_cats_val)
print('total validation dog images:', num_dogs_val)
print("--")
print("Total training images:", total_train)
print("Total validation images:", total_val)

batch_size = 128
epochs = 15
IMG_HEIGHT = 150
IMG_WIDTH = 150

"""## Data preparation
Format the images into appropriately pre-processed floating point tensors before feeding to the network:

1. Read images from the disk.
2. Decode contents of these images and convert it into proper grid format as per their RGB content.
3. Convert them into floating point tensors.
4. Rescale the tensors from values between 0 and 255 to values between 0 and 1, as neural networks prefer to deal with small input values.

Fortunately, all these tasks can be done with the `ImageDataGenerator` class provided by `tf.keras`. It can read images from disk and preprocess them into proper tensors. It will also set up generators that convert these images into batches of tensors—helpful when training the network.
"""

train_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)
validation_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)

train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,
                                                           directory=train_dir,
                                                           shuffle=True,
                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                           class_mode='binary')

val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,
                                                              directory=validation_dir,
                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                              class_mode='binary')

"""## Visualizing the training images
Visualize the training images by extracting a batch of images from the training generator—which is 32 images in this example—then plot five of them with matplotlib.
"""

sample_training_images, sample_training_labels = next(train_data_gen)

"""The `next` function returns a batch from the dataset. The return value of `next` function is in form of `(x_train, y_train)` where x_train is training features and y_train, its labels."""

# lets plot some images
classes = ['cat', 'dog']

def plotImages(images_arr):
    plt.figure(figsize=(10,10))
    for i in range(len(images_arr)):
        img = images_arr[i]
        plt.subplot(5, 5, i+1)
        plt.imshow(img)
        plt.xticks([])
        plt.yticks([])
        plt.grid(False)
    plt.show()

plotImages(sample_training_images[:5])

"""## Create the model"""

model = tf.keras.Sequential()
model.add(tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)))
model.add(tf.keras.layers.MaxPooling2D())
model.add(tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'))
model.add(tf.keras.layers.MaxPooling2D())
model.add(tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'))
model.add(tf.keras.layers.MaxPooling2D())
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(512, activation='relu'))
model.add(tf.keras.layers.Dense(1))

model.summary()

"""## Compile the model"""

model.compile(optimizer='adam',
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'])

"""## Train the model
Use the `fit_generator` method of the `ImageDataGenerator` class to train the network.
"""

history = model.fit_generator(
    train_data_gen,
    steps_per_epoch=total_train // batch_size,
    epochs=epochs,
    validation_data=val_data_gen,
    validation_steps=total_val // batch_size
)

"""### Visualization training results"""

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(range(epochs), history.history['accuracy'], label='Training Accuracy')
plt.plot(range(epochs), history.history['val_accuracy'], label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(range(epochs), history.history['loss'], label='Training Loss')
plt.plot(range(epochs), history.history['val_loss'], label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

"""**Khatarnaak wala `Overfitting`**

## Overfitting
There are multiple ways to fight overfitting in the training process. In this tutorial, we'll use `data augmentation` and add `dropout` to our model.

### Data augmentation
Overfitting generally occurs when there are a `small` number of training examples. One way to fix this problem is to `augment` the dataset so that it has a sufficient number of training examples. Data augmentation takes the approach of generating more training data from existing training samples by augmenting the samples using random transformations that yield believable-looking images. The goal is the model will never see the exact same picture twice during training. This helps expose the model to more aspects of the data and generalize better.

Implement this in tf.keras using the ImageDataGenerator class. Pass different transformations to the dataset and it will take care of applying it during the training process.

#### Augment and visualize data
Begin by applying random horizontal flip augmentation to the dataset and see how individual images look like after the transformation.

#### Apply horizontal flip
Pass horizontal_flip as an argument to the ImageDataGenerator class and set it to True to apply this augmentation.
"""

image_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, horizontal_flip=True)

train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,
                                               directory=train_dir,
                                               shuffle=True,
                                               target_size=(IMG_HEIGHT, IMG_WIDTH))

# let's see for one e.g.

augmented_images =  [train_data_gen[0][0][0] for i in range(5)]

plotImages(augmented_images)

"""#### Randomly rotate the image
Let's take a look at a different augmentation called rotation and apply 45 degrees of rotation randomly to the training examples.
"""

image_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, rotation_range=45)

train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,
                                               directory=train_dir,
                                               shuffle=True,
                                               target_size=(IMG_HEIGHT, IMG_WIDTH))

augmented_images = [train_data_gen[0][0][0] for i in range(5)]

plotImages(augmented_images)

"""#### Apply zoom augmentation
apply zoom upto 50% randomly to the dataset
"""

image_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, zoom_range=0.5)

train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,
                                               directory=train_dir,
                                               shuffle=True,
                                               target_size=(IMG_HEIGHT, IMG_WIDTH))
augmented_images = [train_data_gen[0][0][0] for i in range(5)]

plotImages(augmented_images)

"""#### Put it all together"""

image_gen_train = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,
                                                                  rotation_range=45,
                                                                  width_shift_range=.15,
                                                                  horizontal_flip=True,
                                                                  zoom_range=0.5)

train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,
                                                    directory=train_dir,
                                                    shuffle=True,
                                                    target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                    class_mode='binary')

augmented_images = [train_data_gen[0][0][0] for i in range(5)]

plotImages(augmented_images)

"""### Create validation data generator
Generally, only apply data augmentation to the training examples. In this case, only rescale the validation images and convert them into batches using `ImageDataGenerator.`
"""

image_gen_val = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)

val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,
                                                 directory=validation_dir,
                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                 class_mode='binary')

"""## Dropout
Another technique to reduce overfitting is to introduce `dropout` to the network. It is a form of **`regularization`** that forces the weights in the network to take `only small values`, which makes the distribution of weight values more regular and the network can reduce overfitting on small training examples.

When we apply dropout to a layer it randomly drops out (set to zero) number of output units from the applied layer during the training process. Dropout takes a fractional number as its input value, in the form such as 0.1, 0.2, 0.4, etc. This means dropping out 10%, 20% or 40% of the output units randomly from the applied layer.

When appling 0.1 dropout to a certain layer, it randomly kills 10% of the output units in each training epoch.

Create a network architecture with this new dropout feature and apply it to different convolutions and fully-connected layers.

## Creating a new networks with Dropouts
Here we apply dropout to first and last max pool layers.
"""

model_new = tf.keras.models.Sequential([
                  tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu',
                                         input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),
                   tf.keras.layers.MaxPooling2D(),
                   tf.keras.layers.Dropout(0.2),
                   tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),
                   tf.keras.layers.MaxPooling2D(),
                   tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),
                   tf.keras.layers.MaxPooling2D(),
                   tf.keras.layers.Dropout(0.2),
                   tf.keras.layers.Flatten(),
                   tf.keras.layers.Dense(512, activation='relu'),
                   tf.keras.layers.Dense(1)
])

"""## Compile the model"""

model_new.compile(optimizer='adam',
                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
                  metrics=['accuracy'])
model.summary()

"""## Train the model"""

history = model_new.fit_generator(
        train_data_gen,
        steps_per_epoch=total_train//batch_size,
        epochs=epochs,
        validation_data=val_data_gen,
        validation_steps=total_val//batch_size
)

## Visualize the model

plt.figure(figsize=(8,8))
plt.subplot(1,2,1)
plt.plot(range(epochs), history.history['accuracy'], label='Training Acc')
plt.plot(range(epochs), history.history['val_accuracy'], label='Validation Acc')
plt.title('Accuracy')
plt.legend(loc='lower right')

plt.subplot(1,2,2)
plt.plot(range(epochs), history.history['loss'], label='Training Loss')
plt.plot(range(epochs), history.history['val_loss'], label='Validation Loss')
plt.title('Loss')
plt.legend(loc='upper right')
plt.show()

"""THANK YOU!!!"""

